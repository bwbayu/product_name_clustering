{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair = pd.read_csv('data/clean/clean_dataset.csv')\n",
    "df_flair = df_flair[['name', 'name_length']]\n",
    "df_flair.head()\n",
    "df_stanza = df_flair.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-27 17:45:17,482 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:22,433 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:27,190 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:30,965 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:34,871 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# load POS taggers model\n",
    "pos_custom_id = SequenceTagger.load('resources/taggers/stacked-upos/best-model.pt')\n",
    "pos_custom_multi = SequenceTagger.load('resources/taggers/stacked-upos-en/best-model.pt')\n",
    "pos_multiCorpus = SequenceTagger.load('resources/taggers/multiCorpus-upos/best-model.pt')\n",
    "pos_bert_id = SequenceTagger.load('resources/taggers/bert-id-upos/best-model.pt')\n",
    "pos_bert_multi = SequenceTagger.load('resources/taggers/bert-multi-upos/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract nouns from text\n",
    "def extract_noun_custom(text, tag_pos):\n",
    "    try:\n",
    "        # tokens = re.split(r'[^\\w]+', text.lower())\n",
    "        # cleaned_text = ' '.join(filter(None, tokens))\n",
    "        cleaned_text = text.lower()\n",
    "        \n",
    "        sentence = Sentence(cleaned_text)\n",
    "        tag_pos.predict(sentence)\n",
    "\n",
    "        filtered_words = []\n",
    "        # for token in sentence:\n",
    "        #     if token.get_label('upos').value in ['NOUN']:\n",
    "        #         filtered_words.append(token.text)\n",
    "        \n",
    "        if(len(filtered_words) == 0):\n",
    "            for token in sentence:\n",
    "                if token.get_label('upos').value in ['NOUN', 'PROPN']:\n",
    "                    filtered_words.append(token.text)\n",
    "\n",
    "        if(len(filtered_words) == 0):\n",
    "            for token in sentence:\n",
    "                if token.get_label('upos').value not in ['PUNCT', 'NUM']:\n",
    "                    filtered_words.append(token.text)\n",
    "        \n",
    "        if(len(filtered_words) == 0):\n",
    "            return text\n",
    "        \n",
    "        return ' '.join(filtered_words)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}. Exception: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply POS taggers to extract nouns\n",
    "df_flair['custom_id_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_custom_id))\n",
    "df_flair['custom_multi_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_custom_multi))\n",
    "df_flair['multiCorpus_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_multiCorpus))\n",
    "df_flair['bert_id_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_bert_id))\n",
    "df_flair['bert_multi_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_bert_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAIR - BERT - ID V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>multiCorpus_noun</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, multiCorpus_noun, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST !!!\n",
    "df_flair_bert_idv1 = df_flair[['name', 'multiCorpus_noun', 'name_length']].copy()\n",
    "df_flair_bert_idv1['name_length'] = df_flair_bert_idv1['multiCorpus_noun'].apply(lambda x: len(x))\n",
    "\n",
    "df_flair_bert_idv1[df_flair_bert_idv1['name_length'] == 0][['name', 'multiCorpus_noun', 'name_length']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(df_flair_bert_idv1['multiCorpus_noun']).split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# words_below_10 = [(word, count) for word, count in word_counts.items() if count < 10]\n",
    "\n",
    "# for word, count in words_below_10:\n",
    "#     print(f\"{word}: {count}\")\n",
    "\n",
    "words_below_10 = [word for word, count in word_counts.items() if count < 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(text, words_to_remove):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in words_to_remove]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1['multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun'].apply(lambda x: remove_words(x, words_below_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>multiCorpus_noun</th>\n",
       "      <th>multiCorpus_noun_rm10</th>\n",
       "      <th>multiCorpus_noun_rm20</th>\n",
       "      <th>multiCorpus_noun_rm30</th>\n",
       "      <th>multiCorpus_noun_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, multiCorpus_noun, multiCorpus_noun_rm10, multiCorpus_noun_rm20, multiCorpus_noun_rm30, multiCorpus_noun_rm40, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flair_bert_idv1['name_length'] = df_flair_bert_idv1['multiCorpus_noun_rm40'].apply(lambda x: len(x))\n",
    "\n",
    "df_flair_bert_idv1[df_flair_bert_idv1['name_length'] == 0][['name', 'multiCorpus_noun', 'multiCorpus_noun_rm10', 'multiCorpus_noun_rm20', 'multiCorpus_noun_rm30', 'multiCorpus_noun_rm40', 'name_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.loc[df_flair_bert_idv1['name_length'] == 0, 'multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun_rm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.to_csv('data/clean/clean_dataset_posBERTV1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(df_flair_bert_idv1['multiCorpus_noun']).split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "for word, count in word_counts.most_common(1000):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_word = ['pcs', 'premium', 'inch', 'cm', 'ml', 'x', 'new', 'ukuran', 'kg', 'import', \n",
    "               'gr', 'size', 'meter', 'liter', 'gram', 'l', 'ori', 'indonesia', 'korea', \n",
    "               'm', 's', 'mm', 'the', 'in', 'watt', 'korean', 'c', 'edition', 'a', '100ml', \n",
    "               'xl', 'b', 'japan', 'kualitas', 'g', 'kekinian', 'v', '3in1', 'termurah', \n",
    "               'bpom', 'w', 'dll', 'r', 'h', 'gb', 't', 'k', '8gb']\n",
    "\n",
    "def remove_specific_words(text, remove_word):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in remove_word]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df_flair_bert_idv1['multiCorpus_noun'] = df_flair_bert_idv1['multiCorpus_noun'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm10'] = df_flair_bert_idv1['multiCorpus_noun_rm10'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm20'] = df_flair_bert_idv1['multiCorpus_noun_rm20'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm30'] = df_flair_bert_idv1['multiCorpus_noun_rm30'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun_rm40'].apply(lambda x: remove_specific_words(x, remove_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>multiCorpus_noun</th>\n",
       "      <th>multiCorpus_noun_rm10</th>\n",
       "      <th>multiCorpus_noun_rm20</th>\n",
       "      <th>multiCorpus_noun_rm30</th>\n",
       "      <th>multiCorpus_noun_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, multiCorpus_noun, multiCorpus_noun_rm10, multiCorpus_noun_rm20, multiCorpus_noun_rm30, multiCorpus_noun_rm40, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flair_bert_idv1['name_length'] = df_flair_bert_idv1['multiCorpus_noun_rm40'].apply(lambda x: len(x))\n",
    "\n",
    "df_flair_bert_idv1[df_flair_bert_idv1['name_length'] == 0][['name', 'multiCorpus_noun', 'multiCorpus_noun_rm10', 'multiCorpus_noun_rm20', 'multiCorpus_noun_rm30', 'multiCorpus_noun_rm40', 'name_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.loc[df_flair_bert_idv1['name_length'] == 0, 'multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun_rm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.to_csv('data/clean/clean_dataset_posBERTV1-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_text = df_flair_bert_idv1['name'].iloc[52].lower()\n",
    "# sentence = Sentence(cleaned_text)\n",
    "# pos_multiCorpus.predict(sentence)\n",
    "# for token in sentence:\n",
    "#     print(f\"{token.text} -> {token.get_label('upos')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
