{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 11.8MB/s]                    \n",
      "2024-12-28 16:50:14 INFO: Downloading default packages for language: id (Indonesian) ...\n",
      "2024-12-28 16:50:15 INFO: File exists: C:\\Users\\User\\stanza_resources\\id\\default.zip\n",
      "2024-12-28 16:50:17 INFO: Finished downloading models and saved to C:\\Users\\User\\stanza_resources.\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 5.27MB/s]                    \n",
      "2024-12-28 16:50:18 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-12-28 16:50:19 INFO: File exists: C:\\Users\\User\\stanza_resources\\en\\default.zip\n",
      "2024-12-28 16:50:23 INFO: Finished downloading models and saved to C:\\Users\\User\\stanza_resources.\n",
      "2024-12-28 16:50:23 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 5.10MB/s]                    \n",
      "2024-12-28 16:50:23 WARNING: Language id package default expects mwt, which has been added\n",
      "2024-12-28 16:50:23 INFO: Loading these models for language: id (Indonesian):\n",
      "==========================\n",
      "| Processor | Package    |\n",
      "--------------------------\n",
      "| tokenize  | gsd        |\n",
      "| mwt       | gsd        |\n",
      "| pos       | gsd_charlm |\n",
      "==========================\n",
      "\n",
      "2024-12-28 16:50:23 INFO: Using device: cuda\n",
      "2024-12-28 16:50:23 INFO: Loading: tokenize\n",
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\stanza\\models\\tokenization\\trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-28 16:50:23 INFO: Loading: mwt\n",
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\stanza\\models\\mwt\\trainer.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-28 16:50:23 INFO: Loading: pos\n",
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\stanza\\models\\pos\\trainer.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\stanza\\models\\common\\pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "c:\\Users\\User\\Documents\\Code\\env\\lib\\site-packages\\stanza\\models\\common\\char_model.py:262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-28 16:50:24 INFO: Done loading processors!\n",
      "2024-12-28 16:50:24 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 5.59MB/s]                    \n",
      "2024-12-28 16:50:24 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2024-12-28 16:50:24 INFO: Using device: cuda\n",
      "2024-12-28 16:50:24 INFO: Loading: tokenize\n",
      "2024-12-28 16:50:24 INFO: Loading: pos\n",
      "2024-12-28 16:50:25 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "\n",
    "import stanza\n",
    "stanza.download('id')\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='id', processors='tokenize,pos', use_gpu=True)\n",
    "nlp_en = stanza.Pipeline(lang='en', processors='tokenize,pos', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gamis Pria Dewasa Premium / Jubah Pakistan Polos</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buket Bunga Mawar Flanel / Bunga wisuda / Bung...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mika Sen Depan Supra Fit New Kaca Lampu Sein D...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blazer wanita jumbo big size stik balik / plus...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buku Ilmu Sosial Budaya Dasar Perspektif Baru ...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  name_length\n",
       "0   Gamis Pria Dewasa Premium / Jubah Pakistan Polos           38\n",
       "1  Buket Bunga Mawar Flanel / Bunga wisuda / Bung...           11\n",
       "2  Mika Sen Depan Supra Fit New Kaca Lampu Sein D...           10\n",
       "3  Blazer wanita jumbo big size stik balik / plus...           24\n",
       "4  Buku Ilmu Sosial Budaya Dasar Perspektif Baru ...           69"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flair = pd.read_csv('data/clean/clean_dataset.csv')\n",
    "df_stanza = df_flair[['name', 'clean_name', 'name_length']]\n",
    "df_flair = df_flair[['name', 'name_length']]\n",
    "df_flair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-27 17:45:17,482 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:22,433 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:27,190 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:30,965 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n",
      "2024-12-27 17:45:34,871 SequenceTagger predicts: Dictionary with 19 tags: NOUN, PROPN, PUNCT, VERB, ADP, PRON, ADJ, NUM, DET, CCONJ, ADV, AUX, SCONJ, PART, SYM, X, INTJ, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# load POS taggers model\n",
    "pos_custom_id = SequenceTagger.load('resources/taggers/stacked-upos/best-model.pt')\n",
    "pos_custom_multi = SequenceTagger.load('resources/taggers/stacked-upos-en/best-model.pt')\n",
    "pos_multiCorpus = SequenceTagger.load('resources/taggers/multiCorpus-upos/best-model.pt')\n",
    "pos_bert_id = SequenceTagger.load('resources/taggers/bert-id-upos/best-model.pt')\n",
    "pos_bert_multi = SequenceTagger.load('resources/taggers/bert-multi-upos/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract nouns from text\n",
    "def extract_noun_custom(text, tag_pos):\n",
    "    try:\n",
    "        # tokens = re.split(r'[^\\w]+', text.lower())\n",
    "        # cleaned_text = ' '.join(filter(None, tokens))\n",
    "        cleaned_text = text.lower()\n",
    "        \n",
    "        sentence = Sentence(cleaned_text)\n",
    "        tag_pos.predict(sentence)\n",
    "\n",
    "        filtered_words = []\n",
    "        # for token in sentence:\n",
    "        #     if token.get_label('upos').value in ['NOUN']:\n",
    "        #         filtered_words.append(token.text)\n",
    "        \n",
    "        if(len(filtered_words) == 0):\n",
    "            for token in sentence:\n",
    "                if token.get_label('upos').value in ['NOUN', 'PROPN']:\n",
    "                    filtered_words.append(token.text)\n",
    "\n",
    "        if(len(filtered_words) == 0):\n",
    "            for token in sentence:\n",
    "                if token.get_label('upos').value not in ['PUNCT', 'NUM']:\n",
    "                    filtered_words.append(token.text)\n",
    "        \n",
    "        if(len(filtered_words) == 0):\n",
    "            return text\n",
    "        \n",
    "        return ' '.join(filtered_words)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}. Exception: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply POS taggers to extract nouns\n",
    "df_flair['custom_id_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_custom_id))\n",
    "df_flair['custom_multi_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_custom_multi))\n",
    "df_flair['multiCorpus_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_multiCorpus))\n",
    "df_flair['bert_id_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_bert_id))\n",
    "df_flair['bert_multi_noun'] = df_flair['name'].apply(lambda text: extract_noun_custom(text, pos_bert_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAIR - BERT - ID V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>multiCorpus_noun</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, multiCorpus_noun, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST !!!\n",
    "df_flair_bert_idv1 = df_flair[['name', 'multiCorpus_noun', 'name_length']].copy()\n",
    "df_flair_bert_idv1['name_length'] = df_flair_bert_idv1['multiCorpus_noun'].apply(lambda x: len(x))\n",
    "\n",
    "df_flair_bert_idv1[df_flair_bert_idv1['name_length'] == 0][['name', 'multiCorpus_noun', 'name_length']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(df_flair_bert_idv1['multiCorpus_noun']).split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# words_below_10 = [(word, count) for word, count in word_counts.items() if count < 10]\n",
    "\n",
    "# for word, count in words_below_10:\n",
    "#     print(f\"{word}: {count}\")\n",
    "\n",
    "words_below_10 = [word for word, count in word_counts.items() if count < 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(text, words_to_remove):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in words_to_remove]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1['multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun'].apply(lambda x: remove_words(x, words_below_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>multiCorpus_noun</th>\n",
       "      <th>multiCorpus_noun_rm10</th>\n",
       "      <th>multiCorpus_noun_rm20</th>\n",
       "      <th>multiCorpus_noun_rm30</th>\n",
       "      <th>multiCorpus_noun_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, multiCorpus_noun, multiCorpus_noun_rm10, multiCorpus_noun_rm20, multiCorpus_noun_rm30, multiCorpus_noun_rm40, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flair_bert_idv1['name_length'] = df_flair_bert_idv1['multiCorpus_noun_rm40'].apply(lambda x: len(x))\n",
    "\n",
    "df_flair_bert_idv1[df_flair_bert_idv1['name_length'] == 0][['name', 'multiCorpus_noun', 'multiCorpus_noun_rm10', 'multiCorpus_noun_rm20', 'multiCorpus_noun_rm30', 'multiCorpus_noun_rm40', 'name_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.loc[df_flair_bert_idv1['name_length'] == 0, 'multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun_rm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.to_csv('data/clean/clean_dataset_posBERTV1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(df_flair_bert_idv1['multiCorpus_noun']).split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "for word, count in word_counts.most_common(1000):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_word = ['pcs', 'premium', 'inch', 'cm', 'ml', 'x', 'new', 'ukuran', 'kg', 'import', \n",
    "               'gr', 'size', 'meter', 'liter', 'gram', 'l', 'ori', 'indonesia', 'korea', \n",
    "               'm', 's', 'mm', 'the', 'in', 'watt', 'korean', 'c', 'edition', 'a', '100ml', \n",
    "               'xl', 'b', 'japan', 'kualitas', 'g', 'kekinian', 'v', '3in1', 'termurah', \n",
    "               'bpom', 'w', 'dll', 'r', 'h', 'gb', 't', 'k', '8gb']\n",
    "\n",
    "def remove_specific_words(text, remove_word):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in remove_word]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df_flair_bert_idv1['multiCorpus_noun'] = df_flair_bert_idv1['multiCorpus_noun'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm10'] = df_flair_bert_idv1['multiCorpus_noun_rm10'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm20'] = df_flair_bert_idv1['multiCorpus_noun_rm20'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm30'] = df_flair_bert_idv1['multiCorpus_noun_rm30'].apply(lambda x: remove_specific_words(x, remove_word))\n",
    "df_flair_bert_idv1['multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun_rm40'].apply(lambda x: remove_specific_words(x, remove_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>multiCorpus_noun</th>\n",
       "      <th>multiCorpus_noun_rm10</th>\n",
       "      <th>multiCorpus_noun_rm20</th>\n",
       "      <th>multiCorpus_noun_rm30</th>\n",
       "      <th>multiCorpus_noun_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, multiCorpus_noun, multiCorpus_noun_rm10, multiCorpus_noun_rm20, multiCorpus_noun_rm30, multiCorpus_noun_rm40, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flair_bert_idv1['name_length'] = df_flair_bert_idv1['multiCorpus_noun_rm40'].apply(lambda x: len(x))\n",
    "\n",
    "df_flair_bert_idv1[df_flair_bert_idv1['name_length'] == 0][['name', 'multiCorpus_noun', 'multiCorpus_noun_rm10', 'multiCorpus_noun_rm20', 'multiCorpus_noun_rm30', 'multiCorpus_noun_rm40', 'name_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.loc[df_flair_bert_idv1['name_length'] == 0, 'multiCorpus_noun_rm40'] = df_flair_bert_idv1['multiCorpus_noun_rm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flair_bert_idv1.to_csv('data/clean/clean_dataset_posBERTV1-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_text = df_flair_bert_idv1['name'].iloc[52].lower()\n",
    "# sentence = Sentence(cleaned_text)\n",
    "# pos_multiCorpus.predict(sentence)\n",
    "# for token in sentence:\n",
    "#     print(f\"{token.text} -> {token.get_label('upos')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8061 entries, 0 to 8060\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   name         8061 non-null   object\n",
      " 1   clean_name   8061 non-null   object\n",
      " 2   name_length  8061 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 189.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stanza.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_stanza(text, nlp):\n",
    "    try:\n",
    "        tokens = re.split(r'[^\\w]+', text.lower())\n",
    "        cleaned_text = ' '.join(filter(None, tokens))\n",
    "        \n",
    "        doc = nlp(cleaned_text)\n",
    "        nouns = [word.text for sentence in doc.sentences for word in sentence.words if word.upos in {'NOUN'}]\n",
    "        if(nouns):\n",
    "            return ' '.join(nouns)\n",
    "        \n",
    "        nouns = [word.text for sentence in doc.sentences for word in sentence.words if word.upos in {'NOUN', 'PROPN'}]\n",
    "        if(nouns):\n",
    "            return ' '.join(nouns)\n",
    "          \n",
    "        nouns = [word.text for sentence in doc.sentences for word in sentence.words if word.upos not in {'NUM', 'PUNCT'}]\n",
    "        if(nouns):\n",
    "            return ' '.join(nouns)\n",
    "        \n",
    "        return cleaned_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}. Exception: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stanza['noun_id'] = df_stanza['name'].apply(lambda text: extract_noun_stanza(text, nlp))\n",
    "df_stanza['noun_en'] = df_stanza['name'].apply(lambda text: extract_noun_stanza(text, nlp_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVING WORDS FROM COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_bottom_noun(df, num_delete, column_name):\n",
    "    try:\n",
    "        all_words = ' '.join(df[column_name]).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        words_below = [word for word, count in word_counts.items() if count < num_delete]\n",
    "        remove_words = [\n",
    "            word.text\n",
    "            for word in words_below\n",
    "            for sentence in nlp(word).sentences\n",
    "            for word in sentence.words\n",
    "            if word.upos not in {'NOUN', 'PROPN'}\n",
    "        ]\n",
    "        \n",
    "        return remove_words\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing column: {column_name}. Exception: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_bottom(df, num_delete, column_name):\n",
    "    try:\n",
    "        all_words = ' '.join(df[column_name]).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        words_below = [word for word, count in word_counts.items() if count < num_delete]\n",
    "        \n",
    "        return words_below\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing column: {column_name}. Exception: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specific_words(text, remove_word):\n",
    "    try:\n",
    "        if not text:\n",
    "            return ''\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word.lower() not in remove_word]\n",
    "        return ' '.join(filtered_words)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}. Exception: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_column(df, column_name):\n",
    "    try:\n",
    "        df['name_length'] = df[column_name].apply(lambda x: len(x.split()))\n",
    "        return df[df['name_length'] == 0][['name', 'clean_name', column_name, 'name_length']]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing column: {column_name}. Exception: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STANZA ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>noun_id</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, noun_id, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stanza['name_length'] = df_stanza['noun_id'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_stanza[df_stanza['name_length'] == 0][['name', 'noun_id', 'name_length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10321\n"
     ]
    }
   ],
   "source": [
    "remove_word_10 = remove_word_bottom(df_stanza, 10, 'noun_id')\n",
    "print(len(remove_word_10))\n",
    "df_stanza['noun_id_rm10'] = df_stanza['noun_id'].apply(lambda x: remove_specific_words(x, remove_word_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm10</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Victorinox Rapid Peeler 6.0930</td>\n",
       "      <td>victorinox rapid peeler</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Capacitor/ Kapasitor 50kvar 400V / 86kvar 525V...</td>\n",
       "      <td>capacitor kapasitor kvar v kvar v al nokian</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pen Scriber Holder with SOFT Grip dawning cutt...</td>\n",
       "      <td>pen scriber holder soft grip dawning cutting b...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Klockner Moeller | PS416-MEM-440 | 512kB EEPRO...</td>\n",
       "      <td>klockner moeller ps mem kb eeprom flash cpu me...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BIOAQUA Peach Makeup Remover Wipes 9g×30pcs</td>\n",
       "      <td>bioaqua peach makeup remover wipes g pcs</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8009</th>\n",
       "      <td>Love Beauty Planet Conditioner 400ml</td>\n",
       "      <td>love beauty planet conditioner ml</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>Fort Industrial Plug CEE-023 3 X 32A IP44</td>\n",
       "      <td>fort industrial plug cee x ip</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>Sample Tester Sirup 60ml</td>\n",
       "      <td>sample tester sirup ml</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8044</th>\n",
       "      <td>Portable Hard Shell EVA Travel Carrying Case S...</td>\n",
       "      <td>portable hard shell eva travel carrying case s...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>Viva Queen Perfect Art Eye Liner Pen</td>\n",
       "      <td>viva queen perfect art eye liner pen</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "15                       Victorinox Rapid Peeler 6.0930   \n",
       "46    Capacitor/ Kapasitor 50kvar 400V / 86kvar 525V...   \n",
       "97    Pen Scriber Holder with SOFT Grip dawning cutt...   \n",
       "109   Klockner Moeller | PS416-MEM-440 | 512kB EEPRO...   \n",
       "116         BIOAQUA Peach Makeup Remover Wipes 9g×30pcs   \n",
       "...                                                 ...   \n",
       "8009               Love Beauty Planet Conditioner 400ml   \n",
       "8016          Fort Industrial Plug CEE-023 3 X 32A IP44   \n",
       "8021                           Sample Tester Sirup 60ml   \n",
       "8044  Portable Hard Shell EVA Travel Carrying Case S...   \n",
       "8046               Viva Queen Perfect Art Eye Liner Pen   \n",
       "\n",
       "                                             clean_name noun_id_rm10  \\\n",
       "15                              victorinox rapid peeler                \n",
       "46          capacitor kapasitor kvar v kvar v al nokian                \n",
       "97    pen scriber holder soft grip dawning cutting b...                \n",
       "109   klockner moeller ps mem kb eeprom flash cpu me...                \n",
       "116            bioaqua peach makeup remover wipes g pcs                \n",
       "...                                                 ...          ...   \n",
       "8009                  love beauty planet conditioner ml                \n",
       "8016                      fort industrial plug cee x ip                \n",
       "8021                             sample tester sirup ml                \n",
       "8044  portable hard shell eva travel carrying case s...                \n",
       "8046               viva queen perfect art eye liner pen                \n",
       "\n",
       "      name_length  \n",
       "15              0  \n",
       "46              0  \n",
       "97              0  \n",
       "109             0  \n",
       "116             0  \n",
       "...           ...  \n",
       "8009            0  \n",
       "8016            0  \n",
       "8021            0  \n",
       "8044            0  \n",
       "8046            0  \n",
       "\n",
       "[463 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_id_rm10')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm10</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_id_rm10, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_id_rm10'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_id_rm10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10863\n"
     ]
    }
   ],
   "source": [
    "remove_word_20 = remove_word_bottom(df_stanza, 20, 'noun_id')\n",
    "print(len(remove_word_20))\n",
    "df_stanza['noun_id_rm20'] = df_stanza['noun_id'].apply(lambda x: remove_specific_words(x, remove_word_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm20</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Victorinox Rapid Peeler 6.0930</td>\n",
       "      <td>victorinox rapid peeler</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spanduk / Banner Toko Kelontong / Warung Sembako</td>\n",
       "      <td>spanduk banner toko kelontong warung sembako</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Konseling dan Terapi Qurani</td>\n",
       "      <td>konseling terapi qurani</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Piano Kawai US-50 Semi Grand Upright</td>\n",
       "      <td>piano kawai us semi grand upright</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Capacitor/ Kapasitor 50kvar 400V / 86kvar 525V...</td>\n",
       "      <td>capacitor kapasitor kvar v kvar v al nokian</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>Sample Tester Sirup 60ml</td>\n",
       "      <td>sample tester sirup ml</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8044</th>\n",
       "      <td>Portable Hard Shell EVA Travel Carrying Case S...</td>\n",
       "      <td>portable hard shell eva travel carrying case s...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>Olaif Powerful Cleaning Liquid Detergent 1L- D...</td>\n",
       "      <td>olaif powerful cleaning liquid detergent l det...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>Viva Queen Perfect Art Eye Liner Pen</td>\n",
       "      <td>viva queen perfect art eye liner pen</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>Gurita Potong Rebus Beku Frozen / Octopus Tako...</td>\n",
       "      <td>gurita potong rebus beku frozen octopus takoya...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>865 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "15                       Victorinox Rapid Peeler 6.0930   \n",
       "24     Spanduk / Banner Toko Kelontong / Warung Sembako   \n",
       "32                          Konseling dan Terapi Qurani   \n",
       "45                 Piano Kawai US-50 Semi Grand Upright   \n",
       "46    Capacitor/ Kapasitor 50kvar 400V / 86kvar 525V...   \n",
       "...                                                 ...   \n",
       "8021                           Sample Tester Sirup 60ml   \n",
       "8044  Portable Hard Shell EVA Travel Carrying Case S...   \n",
       "8045  Olaif Powerful Cleaning Liquid Detergent 1L- D...   \n",
       "8046               Viva Queen Perfect Art Eye Liner Pen   \n",
       "8058  Gurita Potong Rebus Beku Frozen / Octopus Tako...   \n",
       "\n",
       "                                             clean_name noun_id_rm20  \\\n",
       "15                              victorinox rapid peeler                \n",
       "24         spanduk banner toko kelontong warung sembako                \n",
       "32                              konseling terapi qurani                \n",
       "45                    piano kawai us semi grand upright                \n",
       "46          capacitor kapasitor kvar v kvar v al nokian                \n",
       "...                                                 ...          ...   \n",
       "8021                             sample tester sirup ml                \n",
       "8044  portable hard shell eva travel carrying case s...                \n",
       "8045  olaif powerful cleaning liquid detergent l det...                \n",
       "8046               viva queen perfect art eye liner pen                \n",
       "8058  gurita potong rebus beku frozen octopus takoya...                \n",
       "\n",
       "      name_length  \n",
       "15              0  \n",
       "24              0  \n",
       "32              0  \n",
       "45              0  \n",
       "46              0  \n",
       "...           ...  \n",
       "8021            0  \n",
       "8044            0  \n",
       "8045            0  \n",
       "8046            0  \n",
       "8058            0  \n",
       "\n",
       "[865 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_id_rm20')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm20</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_id_rm20, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_id_rm20'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_id_rm20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11051\n"
     ]
    }
   ],
   "source": [
    "remove_word_30 = remove_word_bottom(df_stanza, 30, 'noun_id')\n",
    "print(len(remove_word_30))\n",
    "df_stanza['noun_id_rm30'] = df_stanza['noun_id'].apply(lambda x: remove_specific_words(x, remove_word_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm30</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asin amigo/asin kerupuk kualitas super</td>\n",
       "      <td>asin amigo asin kerupuk kualitas super</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Victorinox Rapid Peeler 6.0930</td>\n",
       "      <td>victorinox rapid peeler</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>benih bibit tanaman sayuran repack</td>\n",
       "      <td>benih bibit tanaman sayuran repack</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spanduk / Banner Toko Kelontong / Warung Sembako</td>\n",
       "      <td>spanduk banner toko kelontong warung sembako</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Konseling dan Terapi Qurani</td>\n",
       "      <td>konseling terapi qurani</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8044</th>\n",
       "      <td>Portable Hard Shell EVA Travel Carrying Case S...</td>\n",
       "      <td>portable hard shell eva travel carrying case s...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>Olaif Powerful Cleaning Liquid Detergent 1L- D...</td>\n",
       "      <td>olaif powerful cleaning liquid detergent l det...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>Viva Queen Perfect Art Eye Liner Pen</td>\n",
       "      <td>viva queen perfect art eye liner pen</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>MAKE OVER Lip Amplify Contour Liner | Lip Liner</td>\n",
       "      <td>make lip amplify contour liner lip liner</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>Gurita Potong Rebus Beku Frozen / Octopus Tako...</td>\n",
       "      <td>gurita potong rebus beku frozen octopus takoya...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "10               Asin amigo/asin kerupuk kualitas super   \n",
       "15                       Victorinox Rapid Peeler 6.0930   \n",
       "23                   benih bibit tanaman sayuran repack   \n",
       "24     Spanduk / Banner Toko Kelontong / Warung Sembako   \n",
       "32                          Konseling dan Terapi Qurani   \n",
       "...                                                 ...   \n",
       "8044  Portable Hard Shell EVA Travel Carrying Case S...   \n",
       "8045  Olaif Powerful Cleaning Liquid Detergent 1L- D...   \n",
       "8046               Viva Queen Perfect Art Eye Liner Pen   \n",
       "8048    MAKE OVER Lip Amplify Contour Liner | Lip Liner   \n",
       "8058  Gurita Potong Rebus Beku Frozen / Octopus Tako...   \n",
       "\n",
       "                                             clean_name noun_id_rm30  \\\n",
       "10               asin amigo asin kerupuk kualitas super                \n",
       "15                              victorinox rapid peeler                \n",
       "23                   benih bibit tanaman sayuran repack                \n",
       "24         spanduk banner toko kelontong warung sembako                \n",
       "32                              konseling terapi qurani                \n",
       "...                                                 ...          ...   \n",
       "8044  portable hard shell eva travel carrying case s...                \n",
       "8045  olaif powerful cleaning liquid detergent l det...                \n",
       "8046               viva queen perfect art eye liner pen                \n",
       "8048           make lip amplify contour liner lip liner                \n",
       "8058  gurita potong rebus beku frozen octopus takoya...                \n",
       "\n",
       "      name_length  \n",
       "10              0  \n",
       "15              0  \n",
       "23              0  \n",
       "24              0  \n",
       "32              0  \n",
       "...           ...  \n",
       "8044            0  \n",
       "8045            0  \n",
       "8046            0  \n",
       "8048            0  \n",
       "8058            0  \n",
       "\n",
       "[1319 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_id_rm30')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm30</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_id_rm30, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_id_rm30'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_id_rm30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11151\n"
     ]
    }
   ],
   "source": [
    "remove_word_40 = remove_word_bottom(df_stanza, 40, 'noun_id')\n",
    "print(len(remove_word_40))\n",
    "df_stanza['noun_id_rm40'] = df_stanza['noun_id'].apply(lambda x: remove_specific_words(x, remove_word_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asin amigo/asin kerupuk kualitas super</td>\n",
       "      <td>asin amigo asin kerupuk kualitas super</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Victorinox Rapid Peeler 6.0930</td>\n",
       "      <td>victorinox rapid peeler</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WeRoam Travel Sim Card Taiwan Kuota Besar Data...</td>\n",
       "      <td>weroam travel sim card taiwan kuota besar data...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>benih bibit tanaman sayuran repack</td>\n",
       "      <td>benih bibit tanaman sayuran repack</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spanduk / Banner Toko Kelontong / Warung Sembako</td>\n",
       "      <td>spanduk banner toko kelontong warung sembako</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>Olaif Powerful Cleaning Liquid Detergent 1L- D...</td>\n",
       "      <td>olaif powerful cleaning liquid detergent l det...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>Viva Queen Perfect Art Eye Liner Pen</td>\n",
       "      <td>viva queen perfect art eye liner pen</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>MAKE OVER Lip Amplify Contour Liner | Lip Liner</td>\n",
       "      <td>make lip amplify contour liner lip liner</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>Gurita Potong Rebus Beku Frozen / Octopus Tako...</td>\n",
       "      <td>gurita potong rebus beku frozen octopus takoya...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>Daging Kambing Mentah, Segar 1kg Khusus INSTAN...</td>\n",
       "      <td>daging kambing mentah segar kg khusus instan s...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1842 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "10               Asin amigo/asin kerupuk kualitas super   \n",
       "15                       Victorinox Rapid Peeler 6.0930   \n",
       "21    WeRoam Travel Sim Card Taiwan Kuota Besar Data...   \n",
       "23                   benih bibit tanaman sayuran repack   \n",
       "24     Spanduk / Banner Toko Kelontong / Warung Sembako   \n",
       "...                                                 ...   \n",
       "8045  Olaif Powerful Cleaning Liquid Detergent 1L- D...   \n",
       "8046               Viva Queen Perfect Art Eye Liner Pen   \n",
       "8048    MAKE OVER Lip Amplify Contour Liner | Lip Liner   \n",
       "8058  Gurita Potong Rebus Beku Frozen / Octopus Tako...   \n",
       "8059  Daging Kambing Mentah, Segar 1kg Khusus INSTAN...   \n",
       "\n",
       "                                             clean_name noun_id_rm40  \\\n",
       "10               asin amigo asin kerupuk kualitas super                \n",
       "15                              victorinox rapid peeler                \n",
       "21    weroam travel sim card taiwan kuota besar data...                \n",
       "23                   benih bibit tanaman sayuran repack                \n",
       "24         spanduk banner toko kelontong warung sembako                \n",
       "...                                                 ...          ...   \n",
       "8045  olaif powerful cleaning liquid detergent l det...                \n",
       "8046               viva queen perfect art eye liner pen                \n",
       "8048           make lip amplify contour liner lip liner                \n",
       "8058  gurita potong rebus beku frozen octopus takoya...                \n",
       "8059  daging kambing mentah segar kg khusus instan s...                \n",
       "\n",
       "      name_length  \n",
       "10              0  \n",
       "15              0  \n",
       "21              0  \n",
       "23              0  \n",
       "24              0  \n",
       "...           ...  \n",
       "8045            0  \n",
       "8046            0  \n",
       "8048            0  \n",
       "8058            0  \n",
       "8059            0  \n",
       "\n",
       "[1842 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_id_rm40')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_id_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_id_rm40, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_id_rm40'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_id_rm40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STANZA EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>noun_en</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, noun_en, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stanza['name_length'] = df_stanza['noun_en'].apply(lambda x: len(x))\n",
    "\n",
    "df_stanza[df_stanza['name_length'] == 0][['name', 'noun_en', 'name_length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9551\n"
     ]
    }
   ],
   "source": [
    "remove_word_10 = remove_word_bottom(df_stanza, 10, 'noun_en')\n",
    "print(len(remove_word_10))\n",
    "df_stanza['noun_en_rm10'] = df_stanza['noun_en'].apply(lambda x: remove_specific_words(x, remove_word_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm10</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Victorinox Rapid Peeler 6.0930</td>\n",
       "      <td>victorinox rapid peeler</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yaxiya Gelang Bayi Perempuan Permata Perhiasan...</td>\n",
       "      <td>yaxiya gelang bayi perempuan permata perhiasan...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BUSI MESIN FOGGING TASCO - SWINGFOG / MERK CHA...</td>\n",
       "      <td>busi mesin fogging tasco swingfog merk champio...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>benih bibit tanaman sayuran repack</td>\n",
       "      <td>benih bibit tanaman sayuran repack</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spanduk / Banner Toko Kelontong / Warung Sembako</td>\n",
       "      <td>spanduk banner toko kelontong warung sembako</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>Sample Tester Sirup 60ml</td>\n",
       "      <td>sample tester sirup ml</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>Setelan Syari Wanita Muslimah Simple Rury one ...</td>\n",
       "      <td>setelan syari wanita muslimah simple rury one ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>(GOSEND/GRAB) LE MINERALE - Air Mineral Galon ...</td>\n",
       "      <td>gosend grab le minerale air mineral galon l se...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>[RCU24] Undangan Kalender Duduk, Undangan Pern...</td>\n",
       "      <td>rcu undangan kalender duduk undangan pernikaha...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>Pakaian Bayi dan Anak Laki-laki Motif Best Friend</td>\n",
       "      <td>pakaian bayi anak laki laki motif best friend</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "15                       Victorinox Rapid Peeler 6.0930   \n",
       "18    Yaxiya Gelang Bayi Perempuan Permata Perhiasan...   \n",
       "19    BUSI MESIN FOGGING TASCO - SWINGFOG / MERK CHA...   \n",
       "23                   benih bibit tanaman sayuran repack   \n",
       "24     Spanduk / Banner Toko Kelontong / Warung Sembako   \n",
       "...                                                 ...   \n",
       "8021                           Sample Tester Sirup 60ml   \n",
       "8026  Setelan Syari Wanita Muslimah Simple Rury one ...   \n",
       "8031  (GOSEND/GRAB) LE MINERALE - Air Mineral Galon ...   \n",
       "8036  [RCU24] Undangan Kalender Duduk, Undangan Pern...   \n",
       "8040  Pakaian Bayi dan Anak Laki-laki Motif Best Friend   \n",
       "\n",
       "                                             clean_name noun_en_rm10  \\\n",
       "15                              victorinox rapid peeler                \n",
       "18    yaxiya gelang bayi perempuan permata perhiasan...                \n",
       "19    busi mesin fogging tasco swingfog merk champio...                \n",
       "23                   benih bibit tanaman sayuran repack                \n",
       "24         spanduk banner toko kelontong warung sembako                \n",
       "...                                                 ...          ...   \n",
       "8021                             sample tester sirup ml                \n",
       "8026  setelan syari wanita muslimah simple rury one ...                \n",
       "8031  gosend grab le minerale air mineral galon l se...                \n",
       "8036  rcu undangan kalender duduk undangan pernikaha...                \n",
       "8040      pakaian bayi anak laki laki motif best friend                \n",
       "\n",
       "      name_length  \n",
       "15              0  \n",
       "18              0  \n",
       "19              0  \n",
       "23              0  \n",
       "24              0  \n",
       "...           ...  \n",
       "8021            0  \n",
       "8026            0  \n",
       "8031            0  \n",
       "8036            0  \n",
       "8040            0  \n",
       "\n",
       "[832 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_en_rm10')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm10</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_en_rm10, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_en_rm10'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_en_rm10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10069\n"
     ]
    }
   ],
   "source": [
    "remove_word_20 = remove_word_bottom(df_stanza, 20, 'noun_en')\n",
    "print(len(remove_word_20))\n",
    "df_stanza['noun_en_rm20'] = df_stanza['noun_en'].apply(lambda x: remove_specific_words(x, remove_word_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm20</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mesin Coding Automatic Cetak Expired Date Prod...</td>\n",
       "      <td>mesin coding automatic cetak expired date prod...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asin amigo/asin kerupuk kualitas super</td>\n",
       "      <td>asin amigo asin kerupuk kualitas super</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Panlandwoo - Gelang Bangle Stainless Wanita Bu...</td>\n",
       "      <td>panlandwoo gelang bangle stainless wanita butter</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Victorinox Rapid Peeler 6.0930</td>\n",
       "      <td>victorinox rapid peeler</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yaxiya Gelang Bayi Perempuan Permata Perhiasan...</td>\n",
       "      <td>yaxiya gelang bayi perempuan permata perhiasan...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>[RCU24] Undangan Kalender Duduk, Undangan Pern...</td>\n",
       "      <td>rcu undangan kalender duduk undangan pernikaha...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037</th>\n",
       "      <td>majalah musik Q Januari 2006</td>\n",
       "      <td>majalah musik q januari</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>Pakaian Bayi dan Anak Laki-laki Motif Best Friend</td>\n",
       "      <td>pakaian bayi anak laki laki motif best friend</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>Olaif Powerful Cleaning Liquid Detergent 1L- D...</td>\n",
       "      <td>olaif powerful cleaning liquid detergent l det...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>Buku Novel Kisah Nyata ANGELA</td>\n",
       "      <td>buku novel kisah nyata angela</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "9     Mesin Coding Automatic Cetak Expired Date Prod...   \n",
       "10               Asin amigo/asin kerupuk kualitas super   \n",
       "11    Panlandwoo - Gelang Bangle Stainless Wanita Bu...   \n",
       "15                       Victorinox Rapid Peeler 6.0930   \n",
       "18    Yaxiya Gelang Bayi Perempuan Permata Perhiasan...   \n",
       "...                                                 ...   \n",
       "8036  [RCU24] Undangan Kalender Duduk, Undangan Pern...   \n",
       "8037                       majalah musik Q Januari 2006   \n",
       "8040  Pakaian Bayi dan Anak Laki-laki Motif Best Friend   \n",
       "8045  Olaif Powerful Cleaning Liquid Detergent 1L- D...   \n",
       "8053                      Buku Novel Kisah Nyata ANGELA   \n",
       "\n",
       "                                             clean_name noun_en_rm20  \\\n",
       "9     mesin coding automatic cetak expired date prod...                \n",
       "10               asin amigo asin kerupuk kualitas super                \n",
       "11     panlandwoo gelang bangle stainless wanita butter                \n",
       "15                              victorinox rapid peeler                \n",
       "18    yaxiya gelang bayi perempuan permata perhiasan...                \n",
       "...                                                 ...          ...   \n",
       "8036  rcu undangan kalender duduk undangan pernikaha...                \n",
       "8037                            majalah musik q januari                \n",
       "8040      pakaian bayi anak laki laki motif best friend                \n",
       "8045  olaif powerful cleaning liquid detergent l det...                \n",
       "8053                      buku novel kisah nyata angela                \n",
       "\n",
       "      name_length  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "15              0  \n",
       "18              0  \n",
       "...           ...  \n",
       "8036            0  \n",
       "8037            0  \n",
       "8040            0  \n",
       "8045            0  \n",
       "8053            0  \n",
       "\n",
       "[1535 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_en_rm20')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm20</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_en_rm20, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_en_rm20'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_en_rm20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10230\n"
     ]
    }
   ],
   "source": [
    "remove_word_30 = remove_word_bottom(df_stanza, 30, 'noun_en')\n",
    "print(len(remove_word_30))\n",
    "df_stanza['noun_en_rm30'] = df_stanza['noun_en'].apply(lambda x: remove_specific_words(x, remove_word_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm30</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buket Bunga Mawar Flanel / Bunga wisuda / Bung...</td>\n",
       "      <td>buket bunga mawar flanel bunga wisuda bunga so...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mesin Coding Automatic Cetak Expired Date Prod...</td>\n",
       "      <td>mesin coding automatic cetak expired date prod...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asin amigo/asin kerupuk kualitas super</td>\n",
       "      <td>asin amigo asin kerupuk kualitas super</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Panlandwoo - Gelang Bangle Stainless Wanita Bu...</td>\n",
       "      <td>panlandwoo gelang bangle stainless wanita butter</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Victorinox Rapid Peeler 6.0930</td>\n",
       "      <td>victorinox rapid peeler</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>[RCU24] Undangan Kalender Duduk, Undangan Pern...</td>\n",
       "      <td>rcu undangan kalender duduk undangan pernikaha...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037</th>\n",
       "      <td>majalah musik Q Januari 2006</td>\n",
       "      <td>majalah musik q januari</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>Pakaian Bayi dan Anak Laki-laki Motif Best Friend</td>\n",
       "      <td>pakaian bayi anak laki laki motif best friend</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>Olaif Powerful Cleaning Liquid Detergent 1L- D...</td>\n",
       "      <td>olaif powerful cleaning liquid detergent l det...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>Buku Novel Kisah Nyata ANGELA</td>\n",
       "      <td>buku novel kisah nyata angela</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "1     Buket Bunga Mawar Flanel / Bunga wisuda / Bung...   \n",
       "9     Mesin Coding Automatic Cetak Expired Date Prod...   \n",
       "10               Asin amigo/asin kerupuk kualitas super   \n",
       "11    Panlandwoo - Gelang Bangle Stainless Wanita Bu...   \n",
       "15                       Victorinox Rapid Peeler 6.0930   \n",
       "...                                                 ...   \n",
       "8036  [RCU24] Undangan Kalender Duduk, Undangan Pern...   \n",
       "8037                       majalah musik Q Januari 2006   \n",
       "8040  Pakaian Bayi dan Anak Laki-laki Motif Best Friend   \n",
       "8045  Olaif Powerful Cleaning Liquid Detergent 1L- D...   \n",
       "8053                      Buku Novel Kisah Nyata ANGELA   \n",
       "\n",
       "                                             clean_name noun_en_rm30  \\\n",
       "1     buket bunga mawar flanel bunga wisuda bunga so...                \n",
       "9     mesin coding automatic cetak expired date prod...                \n",
       "10               asin amigo asin kerupuk kualitas super                \n",
       "11     panlandwoo gelang bangle stainless wanita butter                \n",
       "15                              victorinox rapid peeler                \n",
       "...                                                 ...          ...   \n",
       "8036  rcu undangan kalender duduk undangan pernikaha...                \n",
       "8037                            majalah musik q januari                \n",
       "8040      pakaian bayi anak laki laki motif best friend                \n",
       "8045  olaif powerful cleaning liquid detergent l det...                \n",
       "8053                      buku novel kisah nyata angela                \n",
       "\n",
       "      name_length  \n",
       "1               0  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "15              0  \n",
       "...           ...  \n",
       "8036            0  \n",
       "8037            0  \n",
       "8040            0  \n",
       "8045            0  \n",
       "8053            0  \n",
       "\n",
       "[2149 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_en_rm30')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm30</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_en_rm30, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_en_rm30'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_en_rm30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE WORD THAT HAS LENGTH LESS THAN 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10301\n"
     ]
    }
   ],
   "source": [
    "remove_word_40 = remove_word_bottom(df_stanza, 40, 'noun_en')\n",
    "print(len(remove_word_40))\n",
    "df_stanza['noun_en_rm40'] = df_stanza['noun_en'].apply(lambda x: remove_specific_words(x, remove_word_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buket Bunga Mawar Flanel / Bunga wisuda / Bung...</td>\n",
       "      <td>buket bunga mawar flanel bunga wisuda bunga so...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUAVECITO wax rambut warna abu abu grey silver...</td>\n",
       "      <td>suavecito wax rambut warna abu abu grey silver...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mesin Coding Automatic Cetak Expired Date Prod...</td>\n",
       "      <td>mesin coding automatic cetak expired date prod...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asin amigo/asin kerupuk kualitas super</td>\n",
       "      <td>asin amigo asin kerupuk kualitas super</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Panlandwoo - Gelang Bangle Stainless Wanita Bu...</td>\n",
       "      <td>panlandwoo gelang bangle stainless wanita butter</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>Olaif Powerful Cleaning Liquid Detergent 1L- D...</td>\n",
       "      <td>olaif powerful cleaning liquid detergent l det...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>MAKE OVER Lip Amplify Contour Liner | Lip Liner</td>\n",
       "      <td>make lip amplify contour liner lip liner</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>Glowies Lash Lift Effect With Comb Eyelash Cur...</td>\n",
       "      <td>glowies lash lift effect comb eyelash curler p...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>Buku Novel Kisah Nyata ANGELA</td>\n",
       "      <td>buku novel kisah nyata angela</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>Daging Kambing Mentah, Segar 1kg Khusus INSTAN...</td>\n",
       "      <td>daging kambing mentah segar kg khusus instan s...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2675 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "1     Buket Bunga Mawar Flanel / Bunga wisuda / Bung...   \n",
       "5     SUAVECITO wax rambut warna abu abu grey silver...   \n",
       "9     Mesin Coding Automatic Cetak Expired Date Prod...   \n",
       "10               Asin amigo/asin kerupuk kualitas super   \n",
       "11    Panlandwoo - Gelang Bangle Stainless Wanita Bu...   \n",
       "...                                                 ...   \n",
       "8045  Olaif Powerful Cleaning Liquid Detergent 1L- D...   \n",
       "8048    MAKE OVER Lip Amplify Contour Liner | Lip Liner   \n",
       "8052  Glowies Lash Lift Effect With Comb Eyelash Cur...   \n",
       "8053                      Buku Novel Kisah Nyata ANGELA   \n",
       "8059  Daging Kambing Mentah, Segar 1kg Khusus INSTAN...   \n",
       "\n",
       "                                             clean_name noun_en_rm40  \\\n",
       "1     buket bunga mawar flanel bunga wisuda bunga so...                \n",
       "5     suavecito wax rambut warna abu abu grey silver...                \n",
       "9     mesin coding automatic cetak expired date prod...                \n",
       "10               asin amigo asin kerupuk kualitas super                \n",
       "11     panlandwoo gelang bangle stainless wanita butter                \n",
       "...                                                 ...          ...   \n",
       "8045  olaif powerful cleaning liquid detergent l det...                \n",
       "8048           make lip amplify contour liner lip liner                \n",
       "8052  glowies lash lift effect comb eyelash curler p...                \n",
       "8053                      buku novel kisah nyata angela                \n",
       "8059  daging kambing mentah segar kg khusus instan s...                \n",
       "\n",
       "      name_length  \n",
       "1               0  \n",
       "5               0  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "...           ...  \n",
       "8045            0  \n",
       "8048            0  \n",
       "8052            0  \n",
       "8053            0  \n",
       "8059            0  \n",
       "\n",
       "[2675 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_column = check_empty_column(df_stanza, 'noun_en_rm40')\n",
    "empty_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>noun_en_rm40</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, clean_name, noun_en_rm40, name_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(empty_column) > 0):\n",
    "    df_stanza.loc[df_stanza['name_length'] == 0, 'noun_en_rm40'] = df_stanza['clean_name']\n",
    "\n",
    "check_empty_column(df_stanza, 'noun_en_rm40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8061 entries, 0 to 8060\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   name          8061 non-null   object\n",
      " 1   clean_name    8061 non-null   object\n",
      " 2   name_length   8061 non-null   int64 \n",
      " 3   noun_id       8061 non-null   object\n",
      " 4   noun_en       8061 non-null   object\n",
      " 5   noun_id_rm10  8061 non-null   object\n",
      " 6   noun_id_rm20  8061 non-null   object\n",
      " 7   noun_id_rm30  8061 non-null   object\n",
      " 8   noun_id_rm40  8061 non-null   object\n",
      " 9   noun_en_rm10  8061 non-null   object\n",
      " 10  noun_en_rm20  8061 non-null   object\n",
      " 11  noun_en_rm30  8061 non-null   object\n",
      " 12  noun_en_rm40  8061 non-null   object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 818.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stanza.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stanza.to_csv('data/clean/clean_dataset_posStanza1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
